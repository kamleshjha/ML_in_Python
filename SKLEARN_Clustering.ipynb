{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMkFDhkZoxj+wdZpEB3XsCu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Clustering methods**, one of the most useful unsupervised ML methods, used to find similarity & relationship patterns among data samples. After that, they cluster those samples into groups having similarity based on features. Clustering determines the intrinsic grouping among the present unlabeled data, that‚Äôs why it is important.\n","The Scikit-learn library have sklearn.cluster to perform clustering of unlabeled data. Under this module scikit-leran have the following clustering methods:"],"metadata":{"id":"2L5JfpJJhTDA"}},{"cell_type":"markdown","source":["### KMeans\n","\n","This algorithm computes the centroids and iterates until it finds optimal centroid. It requires the number of clusters to be specified that‚Äôs why it assumes that they are already known. The main logic of this algorithm is to cluster the data separating samples in n number of groups of equal variances by minimizing the criteria known as the inertia. The number of clusters identified by algorithm is represented by ‚ÄòK.\n","Scikit-learn have sklearn.cluster.KMeans module to perform K-Means clustering. While computing cluster centers and value of inertia, the parameter named sample_weight allows sklearn.cluster.KMeans module to assign more weight to some samples.\n"],"metadata":{"id":"ExKEKkmYhbKS"}},{"cell_type":"markdown","source":["**Affinity Propagation**\n","\n","This algorithm is based on the concept of ‚Äòmessage passing‚Äô between different pairs of samples until convergence. It does not require the number of clusters to be specified before running the algorithm. The algorithm has a time complexity of the order ùëÇ(ùëÅ2ùëá), which is the biggest disadvantage of it.\n","Scikit-learn have sklearn.cluster.AffinityPropagation module to perform Affinity Propagation clustering.\n","\n","**Mean Shift**\n","\n","This algorithm mainly discovers blobs in a smooth density of samples. It assigns the datapoints to the clusters iteratively by shifting points towards the highest density of datapoints. Instead of relying on a parameter named bandwidth dictating the size of the region to search through, it automatically sets the number of clusters.\n","Scikit-learn have sklearn.cluster.MeanShift module to perform Mean Shift clustering.\n","\n","**Spectral Clustering**\n","\n","Before clustering, this algorithm basically uses the eigenvalues i.e. spectrum of the similarity matrix of the data to perform dimensionality reduction in fewer dimensions. The use of this algorithm is not advisable when there are large number of clusters.Scikit-learn have sklearn.cluster.SpectralClustering module to perform Spectral clustering.\n","\n","**Hierarchical Clustering**\n","\n","This algorithm builds nested clusters by merging or splitting the clusters successively. This cluster hierarchy is represented as dendrogram i.e. tree. It falls into following two categories:\n","\n","**Agglomerative hierarchical algorithms:** In this kind of hierarchical algorithm, every data point is treated like a single cluster. It then successively agglomerates the pairs of clusters. This uses the bottom-up approach.\n","\n","**Divisive hierarchical algorithms:** In this hierarchical algorithm, all data points are treated as one big cluster. In this the process of clustering involves dividing, by using top-down approach, the one big cluster into various small clusters.\n","\n","Scikit-learn have sklearn.cluster.AgglomerativeClustering module to perform Agglomerative Hierarchical clustering.\n","\n","**DBSCAN**\n","\n","It stands for ‚ÄúDensity-based spatial clustering of applications with noise‚Äù. This algorithm is based on the intuitive notion of ‚Äúclusters‚Äù & ‚Äúnoise‚Äù that clusters are dense regions of the lower density in the data space, separated by lower density regions of data points.\n","Scikit-learn have sklearn.cluster.DBSCAN module to perform DBSCAN clustering. There are two important parameters namely min_samples and eps used by this algorithm to define dense.\n","Higher value of parameter min_samples or lower value of the parameter eps will give an indication about the higher density of data points which is necessary to form a cluster.\n","\n","**OPTICS**\n","\n","It stands for ‚ÄúOrdering points to identify the clustering structure‚Äù. This algorithm also finds density-based clusters in spatial data. It‚Äôs basic working logic is like DBSCAN.\n","It addresses a major weakness of DBSCAN algorithm-the problem of detecting meaningful clusters in data of varying density-by ordering the points of the database in such a way that spatially closest points become neighbors in the ordering.\n","Scikit-learn have sklearn.cluster.OPTICS module to perform OPTICS clustering.\n","\n","**BIRCH**\n","\n","It stands for Balanced iterative reducing and clustering using hierarchies. It is used to perform hierarchical clustering over large data sets. It builds a tree named CFT i.e. Characteristics Feature Tree, for the given data.\n","The advantage of CFT is that the data nodes called CF (Characteristics Feature) nodes holds the necessary information for clustering which further prevents the need to hold the entire input data in memory.\n","\n"],"metadata":{"id":"lo9etjvDhpR9"}},{"cell_type":"markdown","source":["**K-Means Clustering on Scikit-learn Digit dataset**"],"metadata":{"id":"2QpRn7x2jBZb"}},{"cell_type":"markdown","source":["In this example, we will apply K-means clustering on digits dataset. This algorithm will identify similar digits without using the original label information. Implementation is done on Jupyter notebook."],"metadata":{"id":"S0j-5jjFjGDh"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KNGZB_B3hM6q","executionInfo":{"status":"ok","timestamp":1688803799344,"user_tz":-330,"elapsed":3105,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"edc0b49b-96d3-4963-dafc-5fe976734d09"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1797, 64)"]},"metadata":{},"execution_count":1}],"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import seaborn as sns; sns.set()\n","import numpy as np\n","from sklearn.cluster import KMeans\n","from sklearn.datasets import load_digits\n","digits = load_digits()\n","digits.data.shape"]},{"cell_type":"markdown","source":["This output shows that digit dataset is having 1797 samples with 64 features.\n","Now, perform the K-Means clustering as follows:"],"metadata":{"id":"2WTYm38qjeiP"}},{"cell_type":"code","source":["kmeans = KMeans(n_clusters=10, random_state=0)\n","clusters = kmeans.fit_predict(digits.data)\n","kmeans.cluster_centers_.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zEsYFY-ijfNq","executionInfo":{"status":"ok","timestamp":1688803878775,"user_tz":-330,"elapsed":2691,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"daf72463-9d93-4ac5-9890-61398de17da1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["(10, 64)"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["This output shows that K-means clustering created 10 clusters with 64 features."],"metadata":{"id":"ogYUJrVEjq5W"}},{"cell_type":"code","source":["fig, ax = plt.subplots(2, 5, figsize=(8, 3))\n","centers = kmeans.cluster_centers_.reshape(10, 8, 8)\n","for axi, center in zip(ax.flat, centers):\n","    axi.set(xticks=[], yticks=[])\n","    axi.imshow(center, interpolation='nearest', cmap=plt.cm.binary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":268},"id":"cS1EJVmkjrvq","executionInfo":{"status":"ok","timestamp":1688803984834,"user_tz":-330,"elapsed":1994,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"9bf3a8b3-b36b-4250-9af9-426dc27a452a"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 800x300 with 10 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAn4AAAD7CAYAAAD0MpkiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAASxElEQVR4nO3dW2wedP3H8W/7dKeu62EHB9nGBtNMJ54SdUIyBxrIphB3gRPQoUETgqdEQQS9YHhnPCRGwWQsJguJF4sjmTKHKNHB8BCYRoMzGcrAzMnKaLf1sM61ff4X/2iM/4t/v7+k+LS/1+v6efdX2qfP89nDxa+t2Ww2AwCAWa/9v/0NAADw6jD8AAAqYfgBAFTC8AMAqIThBwBQCcMPAKAShh8AQCUMPwCAShh+AACV6PhvfwP/qeQikdOnT6ebkZGRdBMRsXz58nTT0ZH/Mbe1taWbVjM5OZluBgYG0s3Q0FC6Kf359vb2ppvu7u50094+O/5NNjExkW5OnTqVbsbGxtJNyfMzouzvefHixelm4cKF6abVlLyenzlzpuiss2fPppuSv7OSv+eurq50EzHzXwdKfv8l780l7xslr00REfPmzUs3Jc+ZBQsWpB7f3t4+5fe1lht+4+Pj6eb+++9PN3v37k03EREPP/xwulm9enW6mQ3Dr+TNeMeOHenmwQcfTDednZ3pJiLi7rvvTjef/exn0032j75VlbyJf/rTn043Tz31VLoZHh5ONxERK1asSDdf+9rX0s11112XblpNybj+3ve+V3RWyftAySD7zGc+k25uvPHGdBNRPhhbRcnwO3DgQLr5whe+kG76+/vTTUTEhg0b0s3tt9+ebq699trU4xctWhSNRmNKj53Z/5wAAGDKDD8AgEoYfgAAlTD8AAAqYfgBAFTC8AMAqIThBwBQCcMPAKAShh8AQCUMPwCAShh+AACVaLm7eg8fPpxuvvGNb6Sb7du3p5uIsguaSy4Pz97R2Gg0Wu5+3yeffDLdPP744+nmlltuSTfPPfdcuomI2LNnT7opuaez5H7nVnTo0KF084Mf/CDdvP71r083W7duTTcREZdcckm6ueyyy4rOmumOHDmSbr785S8XnXXDDTekm4mJiXRT8vy8/vrr003EzL+rd3BwMN3s2rUr3Vx00UXpZv369ekmouy9Y3R0NN1kt0bm/d8nfgAAlTD8AAAqYfgBAFTC8AMAqIThBwBQCcMPAKAShh8AQCUMPwCAShh+AACVMPwAACph+AEAVMLwAwCoRMd0fvGRkZF0s2PHjnRTckH75s2b001ExC9+8Yt0U3KB9MaNG9NNqyn5vTz44IPT8J38X3fccUdR99rXvjbd9PX1FZ01G5w4cSLdzJ07N9187nOfSzfXXHNNuomI6O3tTTfd3d1FZ810L774YrpZunRp0Vk33HBDujly5Ei62b9/f7oZHR1NN7NBs9lMNzfffHO62bBhQ7r54Q9/mG4iIl555ZV0U/K+MX/+/HQzVT7xAwCohOEHAFAJww8AoBKGHwBAJQw/AIBKGH4AAJUw/AAAKmH4AQBUwvADAKiE4QcAUAnDDwCgEoYfAEAlOqbzi//kJz95VZqdO3emm2effTbdREQ8/vjj6eb6669PN+95z3vSTatZvXp1uunt7U039913X7r585//nG4iIrZt25ZuFixYUHTWbNDd3Z1uGo1Guvn2t7+dbl544YV0ExHxsY99LN309PQUnTXTlVxOf/nllxedde+996abl156Kd0sXbo03YyMjKSb2aDkb3n+/Pnp5sCBA+nmoYceSjelTp48mW7a2tqm4Tv5Xz7xAwCohOEHAFAJww8AoBKGHwBAJQw/AIBKGH4AAJUw/AAAKmH4AQBUwvADAKiE4QcAUAnDDwCgEoYfAEAlOqbziz/66KPT+eX/5dChQ+nmySefLDrrxIkT6ebDH/5w0VkzXbPZTDcdHfmn5FVXXZVufvnLX6abiIjdu3enm+uuuy7drFu3Lt20oiuuuCLdfOpTn0o3f/nLX9LNkSNH0k1ExK9//et0s3LlynTT2dmZblrN2rVr0829995bdNYzzzyTboaHh9PNvn370s1f//rXdBMRcfnllxd1rWJsbCzdHDx4MN386Ec/SjfHjx9PNxER11xzTbrp6ekpOmu6+MQPAKAShh8AQCUMPwCAShh+AACVMPwAACph+AEAVMLwAwCohOEHAFAJww8AoBKGHwBAJQw/AIBKGH4AAJUw/AAAKtEx1Qc2m830F1+/fn26eec735luDh8+nG6OHTuWbiIirr322nTz3ve+t+isme4f//hHuhkaGko3JT/fefPmpZuIiDvvvDPd/PSnP00369atSzetaOXKlemm5Gd86NChdLNnz550ExFx4sSJdDMxMVF01kzX1taWbnp6eorO2rJlS7rp6JjyW+C//PjHP043R48eTTcREe973/uKulZR8jr77ne/O9387ne/Szdr165NNxER99xzT7p517veVXTWdPGJHwBAJQw/AIBKGH4AAJUw/AAAKmH4AQBUwvADAKiE4QcAUAnDDwCgEoYfAEAlDD8AgEoYfgAAlTD8AAAqkb+hOmH79u3pZuPGjelm79696ebFF19MNxERn//859PNihUris6a6cbGxtLNrl270k1XV1e6ef7559NNRMTJkyfTTclF8BMTE6nHt7e3R1tbW/qc6VbyHDh48GC6eeSRR9LN0aNH001ExAc+8IF0M3fu3KKzZrpz586lm507dxad9cY3vjHd9Pb2ppv+/v50M2/evHQTEdFsNtNNK70O9PX1pZvXve516ebMmTPp5rbbbks3ERFXXnlluin9/U8Xn/gBAFTC8AMAqIThBwBQCcMPAKAShh8AQCUMPwCAShh+AACVMPwAACph+AEAVMLwAwCohOEHAFAJww8AoBJTvj2+5OLnJUuWpJtFixalmz179qSb1atXp5uIiDe84Q1FXY1KLqY+evRounnooYfSTXd3d7qJiLj55pvTzZYtW9LN+Ph46vFz585Nn/FquHDhQrrZtWtXujl48GC6ueOOO9JNRMTmzZvTTatd0v5qWbhwYbopfW2+66670s3g4GC62bp1a7q5+uqr081s0Gw2081vfvObdFPy+nfVVVelm4iIRqNR1LUSn/gBAFTC8AMAqIThBwBQCcMPAKAShh8AQCUMPwCAShh+AACVMPwAACph+AEAVMLwAwCohOEHAFCJtmbJZXrTqOTbGRgYSDejo6PpJiLi4osvTjcdHVO+EnlWmZycTDenTp1KN8PDw+mmvb3s3zxdXV3ppqenJ92UPGdK7tOebhMTE+mmv78/3YyNjaWbkt9LaTcb7vcsUfJ6fvbs2aKzSu7dLXmN6uzsTDeLFy9ONxERc+bMSTet9Drwav3+h4aG0s2yZcvSTUTZvcCt9DuJaMHhBwDA9PC/egEAKmH4AQBUwvADAKiE4QcAUAnDDwCgEoYfAEAlDD8AgEoYfgAAlTD8AAAqYfgBAFTC8AMAqIThBwBQCcMPAKAShh8AQCUMPwCAShh+AACVMPwAACph+AEAVMLwAwCohOEHAFCJjv/2N/CfRkZG0s3LL7+cbubMmZNuIiKWLl2abubNm1d0FlNz4cKFdNPf31901vj4eLopec50dnamm7a2tnQz3ZrNZro5d+5cuhkYGEg3Jd9bRERvb2+66erqSjet+PvMmpiYSDclr+cREaOjo+mmp6cn3ZT8/huNRrqpVclz5uTJk+mmo6Ns/ixevPhVO2u6tNZ3ExE///nP081HP/rRdLN27dp0ExHxwAMPpJu3v/3tRWcxNSdOnEg3H/zgB4vOOn78eLrZuXNnutm8eXPq8bPpjeWpp55KN1/84hfTzdjYWLqJiPjSl76Ubkqeb7PhH4xDQ0Pp5hOf+ETRWfv37083d911V7q5++67001fX1+6qdXp06fTzUc+8pF0s2rVqnQTEfHVr3413Vx00UVFZ00X/6sXAKAShh8AQCUMPwCAShh+AACVMPwAACph+AEAVMLwAwCohOEHAFAJww8AoBKGHwBAJQw/AIBKTOtdvWfOnEk3t99+e7opudR5fHw83URE3HbbbenmZz/7WbqZDXc7NpvNdHPs2LF0s2PHjnTz9NNPp5uIiJUrV6abwcHBdFPys2tFJXe1HjhwIN2U3KFc+je2b9++dHP11VenmxUrVqSbVvPII4+kmyeeeKLorDVr1qSbxx57LN1s3bo13VxxxRXpZjYoeR0rudv8V7/6VbrZtm1buomI6OzsLOpaiU/8AAAqYfgBAFTC8AMAqIThBwBQCcMPAKAShh8AQCUMPwCAShh+AACVMPwAACph+AEAVMLwAwCohOEHAFCJjun84s8880y6Kblsfffu3emm9NLs97///enmD3/4Q7rZtGlTumk1Jb/Lr3zlK+nm0UcfTTeXXHJJuomIGBoaSjfLly9PN41GI920ovPnz6ebycnJdLNy5cp0MzY2lm4iIubPn59uZsPF7iW6urrSzcc//vGis9auXZtu7r///nRz4cKFdFOr4eHhdPP9738/3XzoQx9KNzfddFO6iYhYtGhRUddKfOIHAFAJww8AoBKGHwBAJQw/AIBKGH4AAJUw/AAAKmH4AQBUwvADAKiE4QcAUAnDDwCgEoYfAEAlDD8AgEp0TOcXP378eLopuWz9yiuvTDdr1qxJNxERGzZsSDdPP/10utm0aVO6aTXPPfdcujl48GC66e3tTTcnT55MNxER58+fTzcXX3xxumlvnx3/JpszZ066WbJkSbopea5NTEykm4iI++67L910d3cXnTXTlbyOrV69uuis/fv3p5uSv+e+vr50U6u///3v6ebUqVPpZvny5enmt7/9bbqJiLj00kvTTclzuq2tLd1M1ex4dwEA4P9l+AEAVMLwAwCohOEHAFAJww8AoBKGHwBAJQw/AIBKGH4AAJUw/AAAKmH4AQBUwvADAKiE4QcAUImO6fzio6Oj6Wbp0qXpZtmyZemmo6PsP73k0vnh4eGis2a6koupb7311nRTctH63r17001ExOnTp9NNV1dX0VmzQaPRSDdDQ0PppuRvbM2aNekmIuKtb31ruin5OcwGfX196abkfSMi4vDhw+mm5DlQ8h5Vq/7+/nQzODiYbh5++OF089hjj6WbiIhLL7003ezYsSPdvPnNb043U+UTPwCAShh+AACVMPwAACph+AEAVMLwAwCohOEHAFAJww8AoBKGHwBAJQw/AIBKGH4AAJUw/AAAKmH4AQBUwvADAKhEx3R+8fXr16ebF154Id2cPXs23YyMjKSbiIjf//736eYd73hH0Vkz3bJly9LNTTfdlG6OHTuWbvbu3ZtuIiIWLVqUbhYuXFh01mwwNjaWbp599tl085a3vCXdTE5OppuIsteoyy67LN00Go1002rGx8fTzeHDh4vOeumll9LNpk2b0s3p06fTTelrQHd3d1HXKlatWpVu2tra0s26devSzbZt29JNRMS+ffvSzXe+8510893vfjf1+Pb29in/7HziBwBQCcMPAKAShh8AQCUMPwCAShh+AACVMPwAACph+AEAVMLwAwCohOEHAFAJww8AoBKGHwBAJQw/AIBKdEznF3/b296Wbtrb81v0k5/8ZLo5f/58uomIeP7559PNxo0bi86a6RYtWpRuFixYkG4GBwfTzZkzZ9JNRERPT0+6GRsbKzprNpg7d2666e3tTTcDAwPp5ty5c+kmIuJvf/tbuil5vens7Ew3rabkb/PrX/960Vl//OMf083w8HC6eeKJJ9LNpk2b0k1ExJ133jnlx/7z76bRaBSdNR1WrVqVbrZs2ZJu/vSnP6Wbkq0REfHKK6+km5GRkXSTfc2YP39+tLW1TemxPvEDAKiE4QcAUAnDDwCgEoYfAEAlDD8AgEoYfgAAlTD8AAAqYfgBAFTC8AMAqIThBwBQCcMPAKAShh8AQCU6pvOLd3d3p5vdu3enmxtvvDHddHSU/ad/85vfTDfr1q0rOmumm+qF0f9uzpw56WbZsmXpZvny5ekmImLBggXpZnJysuis2aDkNeCWW25JN/fcc0+6OXfuXLqJiOjq6ko3ExMTRWfNdCV/zwsXLiw6a2hoKN0cP3483ZS83pw8eTLdREQcO3Zsyo9905veFBERjUaj6Kzp0N6e/2zpgQceSDe33nprutm+fXu6iYhYs2ZNuvnWt76VbubPn596fOb91id+AACVMPwAACph+AEAVMLwAwCohOEHAFAJww8AoBKGHwBAJQw/AIBKGH4AAJUw/AAAKmH4AQBUoq3ZbDb/29/EvxsZGUk3/f396abkHtmIiCVLlqSbkrs9S7+/Gl24cCHdlN6dWfJ7ec1rXpNuSu44bUUlLy8ld+gODAykm9KXvr6+vnTT2dmZbkruOW01JXcUl7yeR5Q9b0p+xiV34WbvXf2nzF3Xc+fOjWazOeOfN+Pj4+nm5ZdfTjeld3V3dHSkm5LdUPKaMdX3p5YbfgAATI+Z/U8DAACmzPADAKiE4QcAUAnDDwCgEoYfAEAlDD8AgEoYfgAAlTD8AAAqYfgBAFTifwA3tqTTnqbZMwAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"cell_type":"markdown","source":["Next, the Python script below will match the learned cluster labels (by K-Means) with the true labels found in them:"],"metadata":{"id":"LcmZVyCckBRw"}},{"cell_type":"code","source":["from scipy.stats import mode\n","labels = np.zeros_like(clusters)\n","for i in range(10):\n","    mask = (clusters == i)\n","    labels[mask] = mode(digits.target[mask])[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ExC47eFJkCRS","executionInfo":{"status":"ok","timestamp":1688804032822,"user_tz":-330,"elapsed":422,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"ef86c901-2b96-4adb-86e8-4c82fb1c1444"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-5-56962d36160d>:5: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n","  labels[mask] = mode(digits.target[mask])[0]\n"]}]},{"cell_type":"markdown","source":["We can also check the accuracy with the help of the below mentioned command."],"metadata":{"id":"gxJheUxRkKoW"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","accuracy_score(digits.target, labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"216opgTnkLpm","executionInfo":{"status":"ok","timestamp":1688804055520,"user_tz":-330,"elapsed":797,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"c5bc7cd9-36f1-4a8a-fb47-7908d57d9a20"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7935447968836951"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["### CLUSTERING PERFORMACE EVALUATION\n","\n","There are various functions with the help of which we can evaluate the performance of clustering algorithms.\n","Following are some important and mostly used functions given by the Scikit-learn for evaluating clustering performance:"],"metadata":{"id":"YyyFbhHMktlz"}},{"cell_type":"markdown","source":["#### **Adjusted Rand Index**\n","\n","Rand Index is a function that computes a similarity measure between two clustering. For this computation rand index considers all pairs of samples and counting pairs that are assigned in the similar or different clusters in the predicted and true clustering. Afterwards, the raw Rand Index score is ‚Äòadjusted for chance‚Äô into the Adjusted Rand Index score by using the following formula: ùê¥ùëëùëóùë¢ùë†ùë°ùëíùëë ùëÖùêº = (ùëÖùêº‚àíùê∏ùë•ùëùùëíùëêùë°ùëíùëë_ùëÖùêº)/(ùëöùëéùë•(ùëÖùêº)‚àí ùê∏ùë•ùëùùëíùëêùë°ùëíùëë_ùëÖùêº)\n","It has two parameters namely labels_true, which is ground truth class labels, and labels_pred, which are clusters label to evaluate."],"metadata":{"id":"qZpMc6V2k1NO"}},{"cell_type":"code","source":["from sklearn.metrics.cluster import adjusted_rand_score\n","labels_true = [0, 0, 1, 1, 1, 1]\n","labels_pred = [0, 0, 2, 2, 3, 3]\n","adjusted_rand_score(labels_true, labels_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MT63_iEZkzne","executionInfo":{"status":"ok","timestamp":1688804276112,"user_tz":-330,"elapsed":15,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"eb702c20-8097-4f33-d37c-6213bc792be7"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4444444444444444"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["Perfect labeling would be scored 1 and bad labelling or independent labelling is scored 0 or negative."],"metadata":{"id":"1p8wdh7WlID7"}},{"cell_type":"markdown","source":["#### Mutual Information Based Score\n","\n","Mutual Information is a function that computes the agreement of the two assignments. It ignores the permutations. There are following versions available:\n","\n","**Normalized Mutual Information (NMI)**\n","Scikit learn have sklearn.metrics.normalized_mutual_info_score module."],"metadata":{"id":"Ew-7Kvi9lLt7"}},{"cell_type":"code","source":["from sklearn.metrics.cluster import normalized_mutual_info_score\n","labels_true = [0, 0, 1, 1, 1, 1]\n","labels_pred = [0, 0, 2, 2, 3, 3]\n","normalized_mutual_info_score (labels_true, labels_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qncynUphlHtF","executionInfo":{"status":"ok","timestamp":1688804348891,"user_tz":-330,"elapsed":520,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"28861bbf-d620-4cba-cfec-a5933785eca6"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7336804366512113"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["#### **Adjusted Mutual Information (AMI)**\n","\n","Scikit learn have sklearn.metrics.adjusted_mutual_info_score module."],"metadata":{"id":"rgMaoAljlZjZ"}},{"cell_type":"code","source":["from sklearn.metrics.cluster import adjusted_mutual_info_score\n","labels_true = [0, 0, 1, 1, 1, 1]\n","labels_pred = [0, 0, 2, 2, 3, 3]\n","adjusted_mutual_info_score (labels_true, labels_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fnzAqkgZlWAn","executionInfo":{"status":"ok","timestamp":1688804394437,"user_tz":-330,"elapsed":10,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"0b6038eb-072d-4c3e-f0ae-be01efffdf5d"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6153846153846159"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["#### **Fowlkes-Mallows Score**\n","\n","The Fowlkes-Mallows function measures the similarity of two clustering of a set of points. It may be defined as the geometric mean of the pairwise precision and recall.\n","\n","Mathematically, ùêπùëÄùëÜ=ùëáùëÉ‚àö(ùëáùëÉ+ùêπùëÉ)(ùëáùëÉ+ùêπùëÅ)\n","\n","\n","Here, TP = True Positive; number of pair of points belonging to the same clusters in true as well as predicted labels both.\n","FP = False Positive; number of pair of points belonging to the same clusters in true labels but not in the predicted labels.\n","FN = False Negative; number of pair of points belonging to the same clusters in the predicted labels but not in the true labels.\n","The Scikit learn has sklearn.metrics.fowlkes_mallows_score module:"],"metadata":{"id":"ThM6U5Dqlk18"}},{"cell_type":"code","source":["from sklearn.metrics.cluster import fowlkes_mallows_score\n","labels_true = [0, 0, 1, 1, 1, 1]\n","labels_pred = [0, 0, 2, 2, 3, 3]\n","\n","fowlkes_mallows_score (labels_true, labels_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dtLOCkdUlrX0","executionInfo":{"status":"ok","timestamp":1688804515289,"user_tz":-330,"elapsed":853,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"6b7ade90-59bb-48e6-dc78-8f7471368318"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6546536707079771"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["#### **Silhouette Coefficient**\n","\n","The Silhouette function will compute the mean Silhouette Coefficient of all samples using the mean intra-cluster distance and the mean nearest-cluster distance for each sample.\n","\n","Mathematically,\n","ùëÜ =(ùëè‚àíùëé)/ùëöùëéùë•(ùëé,ùëè)\n","\n","\n","Here, a is intra-cluster distance.\n","and, b is mean nearest-cluster distance.\n","The Scikit learn have sklearn.metrics.silhouette_score module:"],"metadata":{"id":"Rwe1CS6jmAQ5"}},{"cell_type":"code","source":["from sklearn.metrics import silhouette_score\n","from sklearn.metrics import pairwise_distances\n","from sklearn import datasets\n","import numpy as np\n","from sklearn.cluster import KMeans\n","\n","dataset = datasets.load_iris()\n","X = dataset.data\n","y = dataset.target\n","\n","kmeans_model = KMeans(n_clusters=3, random_state=1).fit(X)\n","labels = kmeans_model.labels_\n","silhouette = silhouette_score(X, labels, metric='euclidean')\n","\n","print(\"Silhouette Score:\", silhouette)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fPDDKcjbmH8P","executionInfo":{"status":"ok","timestamp":1688804671848,"user_tz":-330,"elapsed":1739,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"fe0b51e4-1c0a-4edc-cf23-64add0c3e797"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Silhouette Score: 0.5528190123564095\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["#### Contingency Matrix\n","\n","This matrix will report the intersection cardinality for every trusted pair of (true, predicted). Confusion matrix for classification problems is a square contingency matrix.\n","The Scikit learn have sklearn.metrics.contingency_matrix module.\n","\n"],"metadata":{"id":"cc9ox7j4mp3x"}},{"cell_type":"code","source":["from sklearn.metrics.cluster import contingency_matrix\n","x = [\"a\", \"a\", \"a\", \"b\", \"b\", \"b\"]\n","y = [1, 1, 2, 0, 1, 2]\n","contingency_matrix(x, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JG56cctdmuav","executionInfo":{"status":"ok","timestamp":1688804717403,"user_tz":-330,"elapsed":389,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"aaf2bd98-c556-4133-bed8-f4760ad884ee"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 2, 1],\n","       [1, 1, 1]])"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["The first row of above output shows that among three samples whose true cluster is ‚Äúa‚Äù, none of them is in 0, two of the are in 1 and 1 is in 2. On the other hand, second row shows that among three samples whose true cluster is ‚Äúb‚Äù, 1 is in 0, 1 is in 1 and 1 is in 2."],"metadata":{"id":"lcj8lvtWmyoJ"}}]}