{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNZEliYn4bZz5pS4BpcFfES"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Anamoly Detection\n","Here, we will learn about what is anomaly detection in Sklearn and how it is used in identification of the data points.\n","Anomaly detection is a technique used to identify data points in dataset that does not fit well with the rest of the data. It has many applications in business such as fraud detection, intrusion detection, system health monitoring, surveillance, and predictive maintenance. Anomalies, which are also called outlier, can be divided into following three categories:\n","1. Point anomalies: It occurs when an individual data instance is considered as anomalous w.r.t the rest of the data.\n","2. Contextual anomalies: Such kind of anomaly is context specific. It occurs if a data instance is anomalous in a specific context.\n","3. Collective anomalies: It occurs when a collection of related data instances is anomalous w.r.t entire dataset rather than individual values."],"metadata":{"id":"hO7R6ykl3VGB"}},{"cell_type":"markdown","source":["### Two Methods\n","\n","Two methods namely outlier detection and novelty detection can be used for anomaly detection. It’s necessary to see the distinction between them.\n","\n","**Outlier detection**\n","The training data contains outliers that are far from the rest of the data. Such outliers are defined as observations. That’s the reason, outlier detection estimators always try to fit the region having most concentrated training data while ignoring the deviant observations. It is also known as unsupervised anomaly detection.\n","\n","**Novelty detection**\n","It is concerned with detecting an unobserved pattern in new observations which is not included in training data. Here, the training data is not polluted by the outliers. It is also known as semi-supervised anomaly detection.\n","There are set of ML tools, provided by scikit-learn, which can be used for both outlier detection as well novelty detection. These tools first implementing object learning from the data in an unsupervised by using fit () method as follows:"],"metadata":{"id":"0rNTH8nm3mkw"}},{"cell_type":"markdown","source":["#### Sklearn algorithms for Outlier Detection\n","\n"],"metadata":{"id":"IYoUqg198sxm"}},{"cell_type":"markdown","source":["#### Fitting an elliptic envelop\n","\n","This algorithm assume that regular data comes from a known distribution such as Gaussian distribution. For outlier detection, Scikit-learn provides an object named **covariance.EllipticEnvelop.**\n","This object fits a robust covariance estimate to the data, and thus, fits an ellipse to the central data points. It ignores the points outside the central mode."],"metadata":{"id":"Bfy3q2m38xln"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YGUz6Whh3Fm9","executionInfo":{"status":"ok","timestamp":1687938340202,"user_tz":-330,"elapsed":1359,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"0efcd4a6-272b-4d71-bd26-78d5a56a8002"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-1-ce122a3c7d0d>:4: RuntimeWarning: covariance is not positive-semidefinite.\n","  X = np.random.RandomState(0).multivariate_normal(mean=[0, 0], cov=true_cov,size=500)\n"]}],"source":["import numpy as np\n","from sklearn.covariance import EllipticEnvelope\n","true_cov = np.array([[.5, .6],[.6, .4]])\n","X = np.random.RandomState(0).multivariate_normal(mean=[0, 0], cov=true_cov,size=500)\n","cov = EllipticEnvelope(random_state=0).fit(X)"]},{"cell_type":"code","source":["# Now we can use predict method. It will return 1 for an inlier and -1 for an outlier.\n","cov.predict([[0, 0],[2, 2]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"znp5JHVxBYi-","executionInfo":{"status":"ok","timestamp":1687939325411,"user_tz":-330,"elapsed":420,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"287dcce4-a520-423a-d6d0-ccd7435278cf"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 1, -1])"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["#### Isolation Forest\n","\n","In case of high-dimensional dataset, one efficient way for outlier detection is to use random forests. The scikit-learn provides ensemble.IsolationForest method that isolates the observations by randomly selecting a feature. Afterwards, it randomly selects a value between the maximum and minimum values of the selected features.\n","Here, the number of splitting needed to isolate a sample is equivalent to path length from the root node to the terminating node."],"metadata":{"id":"P0ijFzpqCg1v"}},{"cell_type":"code","source":["### The Python script below will use sklearn. ensemble.IsolationForest method to fit 10 trees on given data:\n","\n","from sklearn.ensemble import IsolationForest\n","import numpy as np\n","X = np.array([[-1, -2], [-3, -3], [-3, -4], [0, 0], [-50, 60]])\n","OUTDClf = IsolationForest(n_estimators=10)\n","OUTDClf.fit(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"id":"ui7D7fHACmle","executionInfo":{"status":"ok","timestamp":1687939690151,"user_tz":-330,"elapsed":403,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"b4287294-5112-49b7-9a49-47f0becd9428"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["IsolationForest(n_estimators=10)"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IsolationForest(n_estimators=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IsolationForest</label><div class=\"sk-toggleable__content\"><pre>IsolationForest(n_estimators=10)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["### Local Outlier Factor\n","\n","Local Outlier Factor (LOF) algorithm is another efficient algorithm to perform outlier detection on high dimension data. The scikit-learn provides neighbors.LocalOutlierFactor method that computes a score, called local outlier factor, reflecting the degree of anomality of the observations. The main logic of this algorithm is to detect the samples that have a substantially lower density than its neighbors. That’s why it measures the local density deviation of given data points w.r.t. their neighbors"],"metadata":{"id":"3tnoVd7BDPd-"}},{"cell_type":"code","source":["#### The Python script given below will use sklearn.neighbors.\n","#### LocalOutlierFactor method to construct NeighborsClassifier class from any array corresponding our data set:\n","\n","from sklearn.neighbors import NearestNeighbors\n","samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n","LOFneigh = NearestNeighbors(n_neighbors=1, algorithm=\"ball_tree\",p=1)\n","LOFneigh.fit(samples)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"id":"ncFv6a0CC75u","executionInfo":{"status":"ok","timestamp":1687939868480,"user_tz":-330,"elapsed":379,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"d296fe1f-0398-48ae-b8f1-9509dad0f10b"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NearestNeighbors(algorithm='ball_tree', n_neighbors=1, p=1)"],"text/html":["<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;ball_tree&#x27;, n_neighbors=1, p=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;ball_tree&#x27;, n_neighbors=1, p=1)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["##### Now, we can ask from this constructed classifier who’s is the closet point to [0.5, 1., 1.5] by using the following python script:\n","\n","print(LOFneigh.kneighbors([[.5, 1., 1.5]]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EffcyLZXDnJd","executionInfo":{"status":"ok","timestamp":1687939968129,"user_tz":-330,"elapsed":375,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"482c35e7-d20e-4337-c910-8532a2c911a0"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["(array([[1.5]]), array([[2]]))\n"]}]},{"cell_type":"markdown","source":["#### One-Class SVM\n","\n","The One-Class SVM, introduced by Schölkopf et al., is the unsupervised Outlier Detection. It is also very efficient in high-dimensional data and estimates the support of a high-dimensional distribution. It is implemented in the Support Vector Machines module in the Sklearn.svm.OneClassSVM object. For defining a frontier, it requires a kernel (mostly used is RBF) and a scalar parameter. For better understanding let’s fit our data with svm.OneClassSVM object:"],"metadata":{"id":"UCMqqkkcEL18"}},{"cell_type":"code","source":["from sklearn.svm import OneClassSVM\n","X = [[0], [0.89], [0.90], [0.91], [1]]\n","OSVMclf = OneClassSVM(gamma='scale').fit(X)"],"metadata":{"id":"vFUZN8mkD_aG","executionInfo":{"status":"ok","timestamp":1687940053984,"user_tz":-330,"elapsed":397,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["OSVMclf.score_samples(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A8ct70KWEUi9","executionInfo":{"status":"ok","timestamp":1687940066652,"user_tz":-330,"elapsed":2,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"9af18fab-e662-4332-9e35-72871f422b66"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1.00296414, 1.43923306, 1.44902238, 1.45691778, 1.43923306])"]},"metadata":{},"execution_count":9}]}]}