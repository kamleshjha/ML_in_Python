{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["PSDmyr6HiffU","cjznQgZPjpez","LpLWSb_fokPy","ieUK4xyXuYg7","c09FryVZvym-","SCQa7syMwyJB","CvSyYwiOxc4N","Ol7YjYPRzV7a","r70eUQzAzinW"],"authorship_tag":"ABX9TyOy3wB91Oy2Rf5UPBE1N8Wp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#### Data Set Loading"],"metadata":{"id":"PSDmyr6HiffU"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F6xDM7dziWiD","executionInfo":{"status":"ok","timestamp":1687413705160,"user_tz":-330,"elapsed":497,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"b14baf56-4606-4334-be8b-9773f470cd06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n","Target name: ['setosa' 'versicolor' 'virginica']\n","\n","First 10 rows of X:\n"," [[5.1 3.5 1.4 0.2]\n"," [4.9 3.  1.4 0.2]\n"," [4.7 3.2 1.3 0.2]\n"," [4.6 3.1 1.5 0.2]\n"," [5.  3.6 1.4 0.2]\n"," [5.4 3.9 1.7 0.4]\n"," [4.6 3.4 1.4 0.3]\n"," [5.  3.4 1.5 0.2]\n"," [4.4 2.9 1.4 0.2]\n"," [4.9 3.1 1.5 0.1]]\n"]}],"source":[" from sklearn.datasets import load_iris\n"," iris = load_iris()\n","\n"," X= iris.data\n"," y= iris.target\n"," feature_names = iris.feature_names\n"," target_names = iris.target_names\n","\n"," print(\"Feature names:\", feature_names)\n"," print(\"Target name:\", target_names)\n"," print(\"\\nFirst 10 rows of X:\\n\",X[:10])"]},{"cell_type":"markdown","source":["#### Splitting the Dataset"],"metadata":{"id":"cjznQgZPjpez"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train,y_train,X_test,y_test = train_test_split(X,y,test_size = 0.3, random_state = 1)\n","\n","print(X_train.shape)\n","print(y_train.shape)\n","\n","print(X_test.shape)\n","print(y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"57xImC9Njs53","executionInfo":{"status":"ok","timestamp":1687413711449,"user_tz":-330,"elapsed":488,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"74f3ec99-4bc4-40d7-9b13-6270d4b88aa3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(105, 4)\n","(45, 4)\n","(105,)\n","(45,)\n"]}]},{"cell_type":"markdown","source":["#### Train the Model"],"metadata":{"id":"LpLWSb_fokPy"}},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn import metrics\n","classifier_knn = KNeighborsClassifier(n_neighbors=3)\n","X_train = X[:120]  # First 120 samples for training\n","y_train = y[:120]\n","X_test = X[120:]   # Last 30 samples for testing\n","y_test = y[120:]\n","\n","classifier_knn.fit(X_train,y_train)\n","y_pred = classifier_knn.predict(X_test)\n","\n","## Finding Accuracy by comparing actual response values(y_test) with predicted response values(y_pred)\n","print(\"Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n","\n","## Providing Sample Data and model will make predictions out of that data\n","sample = [[5,5,3,2],[2,4,3,5]]\n","preds = classifier_knn.predict(sample)\n","pred_species = [iris.target_names[p] for p in preds]\n","print(\"Predictions:\", pred_species)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ze0BT3VDnkvG","executionInfo":{"status":"ok","timestamp":1687413915021,"user_tz":-330,"elapsed":484,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"f2758c55-9d17-4f8d-b14c-abcfaf881418"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.7666666666666667\n","Predictions: ['setosa', 'virginica']\n"]}]},{"cell_type":"markdown","source":["#### Model Persistence\n","\n","Once you train the model, it is desirable that the model should be persist for future use so that we do not need to retrain it again and again. It can be done with the help of dump and load features of joblib package.\n","Consider the example Above in which we will be saving the above trained model (classifier_knn) for future use:"],"metadata":{"id":"ieUK4xyXuYg7"}},{"cell_type":"code","source":["import joblib\n","joblib.dump(classifier_knn, 'iris_classifier_knn.joblib')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"erdGJmIqtU-C","executionInfo":{"status":"ok","timestamp":1687414325234,"user_tz":-330,"elapsed":500,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"7f28928c-87a7-4a71-efba-1ce923181695"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['iris_classifier_knn.joblib']"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["The above code will save the model into file named iris_classifier_knn.joblib. Now, the object can be reloaded from the file with the help of following code:"],"metadata":{"id":"zpYRJvpbu9aY"}},{"cell_type":"code","source":["joblib.load('iris_classifier_knn.joblib')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"id":"fTeWB0H_u1Ec","executionInfo":{"status":"ok","timestamp":1687414385341,"user_tz":-330,"elapsed":4,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"692e9050-1e83-4f70-f321-32dad8220e8b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["KNeighborsClassifier(n_neighbors=3)"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["#### Processing the Data\n","\n","As we are dealing with lots of data and that data is in raw form, before inputting that data to machine learning algorithms, we need to convert it into meaningful data. This process is called preprocessing the data. Scikit-learn has package named preprocessing for this purpose. The preprocessing package has the following techniques.\n","\n","1. Binarisation\n","This preprocessing technique is used when we need to convert our numerical values into Boolean values.\n"],"metadata":{"id":"c09FryVZvym-"}},{"cell_type":"code","source":["#### Here any value Above 0.5 is made as 1 else 0\n","import numpy as np\n","from sklearn import preprocessing\n","Input_data = np.array([[2.1, -1.9, 5.5],\n","[-1.5, 2.4, 3.5],\n","[0.5, -7.9, 5.6],\n","[5.9, 2.3, -5.8]])\n","data_binarized = preprocessing.Binarizer(threshold=0.5).transform(Input_data)\n","print(\"\\nBinarized data:\\n\", data_binarized)"],"metadata":{"id":"saNr18pdvD41","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687414757290,"user_tz":-330,"elapsed":506,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"ccd99cb4-2744-416c-d0d8-6e89e9911a70"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Binarized data:\n"," [[1. 0. 1.]\n"," [0. 1. 1.]\n"," [0. 0. 1.]\n"," [1. 1. 0.]]\n"]}]},{"cell_type":"markdown","source":["#### Mean Removal\n","\n","This technique is used to eliminate the mean from feature vector so that every feature centered on zero."],"metadata":{"id":"SCQa7syMwyJB"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn import preprocessing\n","input_data = np.array([[2.1, -1.9, 5.5],\n","                      [-1.5, 2.4, 3.5],\n","                      [0.5, -7.9, 5.6],\n","                      [5.9, 2.3, -5.8]])\n","\n","#displaying the mean and the standard deviation of the input data\n","print(\"Mean =\", input_data.mean(axis=0))\n","print(\"Stddeviation = \", input_data.std(axis=0))\n","#Removing the mean and the standard deviation of the input data\n","data_scaled = preprocessing.scale(input_data)\n","print(\"Mean_removed =\", data_scaled.mean(axis=0))\n","print(\"Stddeviation_removed =\", data_scaled.std(axis=0))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1l6uDbM0w3p5","executionInfo":{"status":"ok","timestamp":1687414989224,"user_tz":-330,"elapsed":487,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"afac1813-02e2-4b02-8586-d075d154c1b9"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean = [ 1.75  -1.275  2.2  ]\n","Stddeviation =  [2.71431391 4.20022321 4.69414529]\n","Mean_removed = [1.11022302e-16 0.00000000e+00 0.00000000e+00]\n","Stddeviation_removed = [1. 1. 1.]\n"]}]},{"cell_type":"markdown","source":["#### Scaling\n","\n","We use this preprocessing technique for scaling the feature vectors. Scaling of feature vectors is important, because the features should not be synthetically large or small."],"metadata":{"id":"CvSyYwiOxc4N"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn import preprocessing\n","Input_data = np.array([[2.1, -1.9, 5.5],\n","[-1.5, 2.4, 3.5],\n","[0.5, -7.9, 5.6],\n","[5.9, 2.3, -5.8]])\n","\n","data_scaler_minmax = preprocessing.MinMaxScaler(feature_range=(0,1))\n","data_scaled_minmax = data_scaler_minmax.fit_transform(input_data)\n","\n","print (\"\\nMin max scaled data:\\n\", data_scaled_minmax)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AgglGt3GxZQi","executionInfo":{"status":"ok","timestamp":1687415477485,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"7c13b05a-0634-4963-c980-3917f0183c86"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Min max scaled data:\n"," [[0.48648649 0.58252427 0.99122807]\n"," [0.         1.         0.81578947]\n"," [0.27027027 0.         1.        ]\n"," [1.         0.99029126 0.        ]]\n"]}]},{"cell_type":"markdown","source":["### Normalisation\n","\n","We use this preprocessing technique for modifying the feature vectors. Normalisation of feature vectors is necessary so that the feature vectors can be measured at common scale. There are two types of normalisation as follows:"],"metadata":{"id":"Ol7YjYPRzV7a"}},{"cell_type":"markdown","source":["#### L1 Normalisation\n","\n","It is also called Least Absolute Deviations. It modifies the value in such a manner that the sum of the absolute values remains always up to 1 in each row. Following example shows the implementation of L1 normalisation on input data."],"metadata":{"id":"r70eUQzAzinW"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn import preprocessing\n","Input_data = np.array([[2.1, -1.9, 5.5],\n","[-1.5, 2.4, 3.5],\n","[0.5, -7.9, 5.6],\n","[5.9, 2.3, -5.8]])\n","data_normalized_l1 = preprocessing.normalize(input_data, norm='l1')\n","print(\"\\nL1 normalized data:\\n\", data_normalized_l1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sTxpbEwP0ERJ","executionInfo":{"status":"ok","timestamp":1687415956077,"user_tz":-330,"elapsed":12,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"5c39dd1c-89e7-45cb-93b4-f88724353cd8"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","L1 normalized data:\n"," [[ 0.22105263 -0.2         0.57894737]\n"," [-0.2027027   0.32432432  0.47297297]\n"," [ 0.03571429 -0.56428571  0.4       ]\n"," [ 0.42142857  0.16428571 -0.41428571]]\n"]}]},{"cell_type":"markdown","source":["#### L2 Normalisation\n","\n","Also called Least Squares. It modifies the value in such a manner that the sum of the squares remains always up to 1 in each row. Following example shows the implementation of L2 normalisation on input data."],"metadata":{"id":"KF683XZD0VnM"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn import preprocessing\n","Input_data = np.array([[2.1, -1.9, 5.5],\n","[-1.5, 2.4, 3.5],\n","[0.5, -7.9, 5.6],\n","[5.9, 2.3, -5.8]])\n","data_normalized_l2 = preprocessing.normalize(input_data, norm='l2')\n","print(\"\\nL1 normalized data:\\n\", data_normalized_l2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6iqg2NiZ0ukp","executionInfo":{"status":"ok","timestamp":1687415956079,"user_tz":-330,"elapsed":9,"user":{"displayName":"Kamlesh Jha","userId":"17539185982158631763"}},"outputId":"9d884b19-eebf-4bb5-cacd-e26711534383"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","L1 normalized data:\n"," [[ 0.33946114 -0.30713151  0.88906489]\n"," [-0.33325106  0.53320169  0.7775858 ]\n"," [ 0.05156558 -0.81473612  0.57753446]\n"," [ 0.68706914  0.26784051 -0.6754239 ]]\n"]}]}]}